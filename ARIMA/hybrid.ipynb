{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=30240.523, Time=2.28 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=30272.252, Time=0.19 sec\n",
      " ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=30243.723, Time=0.54 sec\n",
      " ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=30241.768, Time=0.77 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0]             : AIC=30270.982, Time=0.17 sec\n",
      " ARIMA(2,1,1)(0,0,0)[0] intercept   : AIC=30234.621, Time=2.66 sec\n",
      " ARIMA(2,1,0)(0,0,0)[0] intercept   : AIC=30239.276, Time=0.76 sec\n",
      " ARIMA(3,1,1)(0,0,0)[0] intercept   : AIC=30236.607, Time=4.12 sec\n",
      " ARIMA(2,1,2)(0,0,0)[0] intercept   : AIC=30236.577, Time=6.50 sec\n",
      " ARIMA(1,1,2)(0,0,0)[0] intercept   : AIC=30234.958, Time=3.86 sec\n",
      " ARIMA(3,1,0)(0,0,0)[0] intercept   : AIC=30240.618, Time=1.05 sec\n",
      " ARIMA(3,1,2)(0,0,0)[0] intercept   : AIC=30237.920, Time=5.87 sec\n",
      " ARIMA(2,1,1)(0,0,0)[0]             : AIC=30233.414, Time=0.94 sec\n",
      " ARIMA(1,1,1)(0,0,0)[0]             : AIC=30239.179, Time=1.16 sec\n",
      " ARIMA(2,1,0)(0,0,0)[0]             : AIC=30237.952, Time=0.39 sec\n",
      " ARIMA(3,1,1)(0,0,0)[0]             : AIC=30235.401, Time=1.76 sec\n",
      " ARIMA(2,1,2)(0,0,0)[0]             : AIC=30235.372, Time=2.71 sec\n",
      " ARIMA(1,1,0)(0,0,0)[0]             : AIC=30242.355, Time=0.28 sec\n",
      " ARIMA(1,1,2)(0,0,0)[0]             : AIC=30233.748, Time=1.51 sec\n",
      " ARIMA(3,1,0)(0,0,0)[0]             : AIC=30239.309, Time=0.48 sec\n",
      " ARIMA(3,1,2)(0,0,0)[0]             : AIC=30236.712, Time=2.50 sec\n",
      "\n",
      "Best model:  ARIMA(2,1,1)(0,0,0)[0]          \n",
      "Total fit time: 40.526 seconds\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601ms/step\n",
      "Hybrid model prediction for next day closing price: $244.92\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input\n",
    "\n",
    "def prepare_data(data, time_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X.append(data[i:(i + time_steps), 0])\n",
    "        y.append(data[i + time_steps, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def hybrid_model(data, time_steps=60):\n",
    "    # Ensure data is numpy array\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        df = data.values\n",
    "    else:\n",
    "        df = np.array(data)\n",
    "    \n",
    "    df = df.reshape(-1, 1)\n",
    "\n",
    "    df = pd.DataFrame(df).ffill().values\n",
    "\n",
    "    # ARIMA model\n",
    "    model_auto = auto_arima(df, start_p=1, start_q=1, max_p=3, max_q=3, m=1,\n",
    "                            d=None, seasonal=False, start_P=0, D=0, trace=True,\n",
    "                            error_action='ignore', suppress_warnings=True, stepwise=True)\n",
    "\n",
    "    arima_model = ARIMA(df, order=model_auto.order)\n",
    "    arima_results = arima_model.fit()\n",
    "\n",
    "    # Get ARIMA residuals\n",
    "    arima_residuals = df - arima_results.fittedvalues.reshape(-1, 1)\n",
    "    arima_residuals = np.nan_to_num(arima_residuals)\n",
    "    \n",
    "    # Prepare data for LSTM\n",
    "    scaler = MinMaxScaler()\n",
    "    residuals_scaled = scaler.fit_transform(arima_residuals)\n",
    "\n",
    "    X, y = prepare_data(residuals_scaled, time_steps)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    # LSTM model\n",
    "    lstm_model = Sequential([\n",
    "        Input(shape=(X.shape[1], 1)),\n",
    "        LSTM(units=50, return_sequences=True), \n",
    "        LSTM(units=50),\n",
    "        Dense(units=1)\n",
    "    ])\n",
    "    lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    lstm_model.fit(X, y, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    # Make hybrid prediction\n",
    "    last_60_days = residuals_scaled[-60:]\n",
    "    X_test = np.array([last_60_days])\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    lstm_prediction = lstm_model.predict(X_test)\n",
    "    lstm_prediction = scaler.inverse_transform(lstm_prediction)\n",
    "\n",
    "    arima_forecast = arima_results.forecast(steps=1)\n",
    "\n",
    "    hybrid_prediction = arima_forecast + lstm_prediction[0][0]\n",
    "\n",
    "    return hybrid_prediction[0]\n",
    "\n",
    "# Example usage with custom data\n",
    "# Assuming you have a CSV file named 'my_stock_data.csv' with a 'Close' column\n",
    "custom_data = pd.read_csv('../Data/SBI Train data.csv')\n",
    "close_prices = custom_data['Close']\n",
    "\n",
    "prediction = hybrid_model(close_prices)\n",
    "print(f\"Hybrid model prediction for next day closing price: ${prediction:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=30240.523, Time=2.25 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=30272.252, Time=0.22 sec\n",
      " ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=30243.723, Time=0.58 sec\n",
      " ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=30241.768, Time=0.82 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0]             : AIC=30270.982, Time=0.15 sec\n",
      " ARIMA(2,1,1)(0,0,0)[0] intercept   : AIC=30234.621, Time=2.72 sec\n",
      " ARIMA(2,1,0)(0,0,0)[0] intercept   : AIC=30239.276, Time=0.84 sec\n",
      " ARIMA(3,1,1)(0,0,0)[0] intercept   : AIC=30236.607, Time=4.21 sec\n",
      " ARIMA(2,1,2)(0,0,0)[0] intercept   : AIC=30236.577, Time=6.49 sec\n",
      " ARIMA(1,1,2)(0,0,0)[0] intercept   : AIC=30234.958, Time=4.04 sec\n",
      " ARIMA(3,1,0)(0,0,0)[0] intercept   : AIC=30240.618, Time=1.13 sec\n",
      " ARIMA(3,1,2)(0,0,0)[0] intercept   : AIC=30237.920, Time=6.01 sec\n",
      " ARIMA(2,1,1)(0,0,0)[0]             : AIC=30233.414, Time=1.07 sec\n",
      " ARIMA(1,1,1)(0,0,0)[0]             : AIC=30239.179, Time=1.18 sec\n",
      " ARIMA(2,1,0)(0,0,0)[0]             : AIC=30237.952, Time=0.35 sec\n",
      " ARIMA(3,1,1)(0,0,0)[0]             : AIC=30235.401, Time=1.82 sec\n",
      " ARIMA(2,1,2)(0,0,0)[0]             : AIC=30235.372, Time=2.42 sec\n",
      " ARIMA(1,1,0)(0,0,0)[0]             : AIC=30242.355, Time=0.29 sec\n",
      " ARIMA(1,1,2)(0,0,0)[0]             : AIC=30233.748, Time=1.49 sec\n",
      " ARIMA(3,1,0)(0,0,0)[0]             : AIC=30239.309, Time=0.54 sec\n",
      " ARIMA(3,1,2)(0,0,0)[0]             : AIC=30236.712, Time=2.61 sec\n",
      "\n",
      "Best model:  ARIMA(2,1,1)(0,0,0)[0]          \n",
      "Total fit time: 41.259 seconds\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step\n",
      "Hybrid model prediction for next day closing price: $245.04\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input\n",
    "\n",
    "def prepare_data(data, time_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X.append(data[i:(i + time_steps), 0])\n",
    "        y.append(data[i + time_steps, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def hybrid_model(data, time_steps=60):\n",
    "    # Ensure data is numpy array\n",
    "    if isinstance(data, pd.Series):\n",
    "        df = data.values\n",
    "    elif isinstance(data, pd.DataFrame):\n",
    "        df = data.values\n",
    "    else:\n",
    "        df = np.array(data)\n",
    "    \n",
    "    df = df.reshape(-1, 1)\n",
    "\n",
    "    df = pd.DataFrame(df).ffill().values\n",
    "\n",
    "    # ARIMA model\n",
    "    model_auto = auto_arima(df, start_p=1, start_q=1, max_p=3, max_q=3, m=1,\n",
    "                            d=None, seasonal=False, start_P=0, D=0, trace=True,\n",
    "                            error_action='ignore', suppress_warnings=True, stepwise=True)\n",
    "\n",
    "    arima_model = ARIMA(df, order=model_auto.order)\n",
    "    arima_results = arima_model.fit()\n",
    "\n",
    "    # Get ARIMA residuals\n",
    "    arima_residuals = df - arima_results.fittedvalues.reshape(-1, 1)\n",
    "    arima_residuals = np.nan_to_num(arima_residuals)\n",
    "\n",
    "    # Prepare data for LSTM\n",
    "    scaler = MinMaxScaler()\n",
    "    residuals_scaled = scaler.fit_transform(arima_residuals)\n",
    "\n",
    "    X, y = prepare_data(residuals_scaled, time_steps)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    # LSTM model\n",
    "    lstm_model = Sequential([\n",
    "        Input(shape=(X.shape[1], 1)),\n",
    "        LSTM(units=50, return_sequences=True), \n",
    "        LSTM(units=50),\n",
    "        Dense(units=1)\n",
    "    ])\n",
    "    lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    lstm_model.fit(X, y, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    # Make hybrid prediction\n",
    "    last_60_days = residuals_scaled[-60:]\n",
    "    X_test = np.array([last_60_days])\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    lstm_prediction = lstm_model.predict(X_test)\n",
    "    lstm_prediction = scaler.inverse_transform(lstm_prediction)\n",
    "\n",
    "    arima_forecast = arima_results.forecast(steps=1)\n",
    "\n",
    "    hybrid_prediction = arima_forecast + lstm_prediction[0][0]\n",
    "\n",
    "    return hybrid_prediction[0]\n",
    "\n",
    "# Example usage with custom data\n",
    "custom_data = pd.read_csv('../Data/SBI Train data.csv')\n",
    "close_prices = custom_data['Close']\n",
    "\n",
    "prediction = hybrid_model(close_prices)\n",
    "print(f\"Hybrid model prediction for next day closing price: ${prediction:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def prepare_data(data, time_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X.append(data[i:(i + time_steps), 0])\n",
    "        y.append(data[i + time_steps, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def hybrid_model(train_data, test_data, time_steps=60):\n",
    "    # Ensure data is numpy array\n",
    "    if isinstance(train_data, pd.Series):\n",
    "        train_df = train_data.values\n",
    "    if isinstance(test_data, pd.DataFrame):\n",
    "        test_df = train_data.values\n",
    "    else:\n",
    "        train_df = np.array(train_data)\n",
    "    \n",
    "    train_df = train_df.reshape(-1, 1)\n",
    "\n",
    "    train_df = pd.DataFrame(train_df).ffill().values\n",
    "\n",
    "    # ARIMA model\n",
    "    model_auto = auto_arima(train_df, start_p=1, start_q=1, max_p=3, max_q=3, m=1,\n",
    "                            d=None, seasonal=False, start_P=0, D=0, trace=True,\n",
    "                            error_action='ignore', suppress_warnings=True, stepwise=True)\n",
    "\n",
    "    arima_model = ARIMA(train_df, order=model_auto.order)\n",
    "    arima_results = arima_model.fit()\n",
    "\n",
    "    # Get ARIMA residuals\n",
    "    arima_residuals = train_df - arima_results.fittedvalues.reshape(-1, 1)\n",
    "    arima_residuals = np.nan_to_num(arima_residuals)\n",
    "\n",
    "    # Prepare data for LSTM\n",
    "    scaler = MinMaxScaler()\n",
    "    residuals_scaled = scaler.fit_transform(arima_residuals)\n",
    "\n",
    "    X, y = prepare_data(residuals_scaled, time_steps)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    # LSTM model\n",
    "    lstm_model = Sequential([\n",
    "        Input(shape=(X.shape[1], 1)),\n",
    "        LSTM(units=50, return_sequences=True), \n",
    "        LSTM(units=50),\n",
    "        Dense(units=1)\n",
    "    ])\n",
    "    lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    lstm_model.fit(X, y, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    # Make predictions for test data\n",
    "    predictions = []\n",
    "    test_data = np.array(test_data).reshape(-1, 1)\n",
    "    combined_data = np.vstack((train_df, test_data))\n",
    "\n",
    "    for i in range(len(test_data)):\n",
    "        # ARIMA prediction\n",
    "        arima_forecast = arima_results.forecast(steps=1)\n",
    "\n",
    "        # LSTM prediction\n",
    "        last_60_days = scaler.transform(combined_data[-(time_steps+1):-1])\n",
    "        X_test = np.array([last_60_days])\n",
    "        X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "        lstm_prediction = lstm_model.predict(X_test)\n",
    "        lstm_prediction = scaler.inverse_transform(lstm_prediction)\n",
    "\n",
    "        # Combine predictions\n",
    "        hybrid_prediction = arima_forecast + lstm_prediction[0][0]\n",
    "        predictions.append(hybrid_prediction[0])\n",
    "\n",
    "        # Update ARIMA model\n",
    "        arima_results = arima_model.append(test_data[i]).fit()\n",
    "\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Load and prepare data\n",
    "train_data = pd.read_csv('../Data/SBI Train data.csv')\n",
    "test_data = pd.read_csv('../Data/SBI Test data.csv')\n",
    "\n",
    "train_close_prices = train_data['Close']\n",
    "test_close_prices = test_data['Close']\n",
    "\n",
    "# Make predictions\n",
    "predictions = hybrid_model(train_close_prices, test_close_prices)\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "mae = mean_absolute_error(test_close_prices, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(test_close_prices, predictions))\n",
    "\n",
    "print(f\"Mean Absolute Error: ${mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: ${rmse:.2f}\")\n",
    "\n",
    "# You can also calculate percentage error\n",
    "mape = np.mean(np.abs((test_close_prices - predictions) / test_close_prices)) * 100\n",
    "print(f\"Mean Absolute Percentage Error: {mape:.2f}%\")\n",
    "\n",
    "# Plot actual vs predicted prices\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(test_data['Date'], test_close_prices, label='Actual Prices')\n",
    "plt.plot(test_data['Date'], predictions, label='Predicted Prices')\n",
    "plt.title('Actual vs Predicted Stock Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def prepare_data(data, time_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X.append(data[i:(i + time_steps), 0])\n",
    "        y.append(data[i + time_steps, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def hybrid_model(train_data, test_data, time_steps=60):\n",
    "    # Ensure data is numpy array\n",
    "    if isinstance(train_data, pd.Series):\n",
    "        train_df = train_data.values\n",
    "    elif isinstance(train_data, pd.DataFrame):\n",
    "        train_df = train_data.values\n",
    "    else:\n",
    "        train_df = np.array(train_data)\n",
    "    \n",
    "    train_df = train_df.reshape(-1, 1)\n",
    "    train_df = pd.DataFrame(train_df).ffill().values\n",
    "\n",
    "    # ARIMA model\n",
    "    model_auto = auto_arima(train_df, start_p=1, start_q=1, max_p=3, max_q=3, m=1,\n",
    "                            d=None, seasonal=False, start_P=0, D=0, trace=True,\n",
    "                            error_action='ignore', suppress_warnings=True, stepwise=True)\n",
    "\n",
    "    arima_model = ARIMA(train_df, order=model_auto.order)\n",
    "    arima_results = arima_model.fit()\n",
    "\n",
    "    # Get ARIMA residuals\n",
    "    arima_residuals = train_df - arima_results.fittedvalues.reshape(-1, 1)\n",
    "    arima_residuals = np.nan_to_num(arima_residuals)\n",
    "\n",
    "    # Prepare data for LSTM\n",
    "    scaler = MinMaxScaler()\n",
    "    residuals_scaled = scaler.fit_transform(arima_residuals)\n",
    "\n",
    "    X, y = prepare_data(residuals_scaled, time_steps)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    # LSTM model\n",
    "    lstm_model = Sequential([\n",
    "        Input(shape=(X.shape[1], 1)),\n",
    "        LSTM(units=50, return_sequences=True), \n",
    "        LSTM(units=50),\n",
    "        Dense(units=1)\n",
    "    ])\n",
    "    lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    lstm_model.fit(X, y, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    # Make predictions for test data\n",
    "    predictions = []\n",
    "    test_data = np.array(test_data).reshape(-1, 1)\n",
    "    combined_data = np.vstack((train_df, test_data))\n",
    "\n",
    "    for i in range(len(test_data)):\n",
    "        # ARIMA prediction\n",
    "        arima_forecast = arima_results.forecast(steps=1)\n",
    "\n",
    "        # LSTM prediction\n",
    "        last_60_days = scaler.transform(combined_data[-(time_steps+1):-1])\n",
    "        X_test = np.array([last_60_days])\n",
    "        X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "        lstm_prediction = lstm_model.predict(X_test)\n",
    "        lstm_prediction = scaler.inverse_transform(lstm_prediction)\n",
    "\n",
    "        # Combine predictions\n",
    "        hybrid_prediction = arima_forecast + lstm_prediction[0][0]\n",
    "        predictions.append(hybrid_prediction[0])\n",
    "\n",
    "        # Update ARIMA model\n",
    "        arima_results = arima_model.append(test_data[i]).fit()\n",
    "\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Load and prepare data\n",
    "train_data = pd.read_csv('../Data/SBI Train data.csv')\n",
    "test_data = pd.read_csv('../Data/SBI Test data.csv')\n",
    "\n",
    "train_close_prices = train_data['Close']\n",
    "test_close_prices = test_data['Close']\n",
    "\n",
    "# Make predictions\n",
    "predictions = hybrid_model(train_close_prices, test_close_prices)\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "mae = mean_absolute_error(test_close_prices, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(test_close_prices, predictions))\n",
    "\n",
    "print(f\"Mean Absolute Error: ${mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: ${rmse:.2f}\")\n",
    "\n",
    "# You can also calculate percentage error\n",
    "mape = np.mean(np.abs((test_close_prices - predictions) / test_close_prices)) * 100\n",
    "print(f\"Mean Absolute Percentage Error: {mape:.2f}%\")\n",
    "\n",
    "# Plot actual vs predicted prices\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(test_data['Date'], test_close_prices, label='Actual Prices')\n",
    "plt.plot(test_data['Date'], predictions, label='Predicted Prices')\n",
    "plt.title('Actual vs Predicted Stock Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "def prepare_data(data, time_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X.append(data[i:(i + time_steps), 0])\n",
    "        y.append(data[i + time_steps, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def create_hybrid_model(train_data, time_steps=60):\n",
    "    # Ensure data is numpy array\n",
    "    if isinstance(train_data, pd.Series):\n",
    "        train_df = train_data.values\n",
    "    elif isinstance(train_data, pd.DataFrame):\n",
    "        train_df = train_data.values\n",
    "    else:\n",
    "        train_df = np.array(train_data)\n",
    "    \n",
    "    train_df = train_df.reshape(-1, 1)\n",
    "    train_df = pd.DataFrame(train_df).ffill().values\n",
    "\n",
    "    # ARIMA model\n",
    "    model_auto = auto_arima(train_df, start_p=1, start_q=1, max_p=3, max_q=3, m=1,\n",
    "                            d=None, seasonal=False, start_P=0, D=0, trace=True,\n",
    "                            error_action='ignore', suppress_warnings=True, stepwise=True)\n",
    "\n",
    "    arima_model = ARIMA(train_df, order=model_auto.order)\n",
    "    arima_results = arima_model.fit()\n",
    "\n",
    "    # Get ARIMA residuals\n",
    "    arima_residuals = train_df - arima_results.fittedvalues.reshape(-1, 1)\n",
    "    arima_residuals = np.nan_to_num(arima_residuals)\n",
    "\n",
    "    # Prepare data for LSTM\n",
    "    scaler = MinMaxScaler()\n",
    "    residuals_scaled = scaler.fit_transform(arima_residuals)\n",
    "\n",
    "    X, y = prepare_data(residuals_scaled, time_steps)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    # LSTM model\n",
    "    lstm_model = Sequential([\n",
    "        Input(shape=(X.shape[1], 1)),\n",
    "        LSTM(units=50, return_sequences=True), \n",
    "        LSTM(units=50),\n",
    "        Dense(units=1)\n",
    "    ])\n",
    "    lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    lstm_model.fit(X, y, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    return arima_results, lstm_model, scaler\n",
    "\n",
    "def save_model(arima_results, lstm_model, scaler, folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    # Save ARIMA model\n",
    "    joblib.dump(arima_results, os.path.join(folder_path, 'arima_model.pkl'))\n",
    "    \n",
    "    # Save LSTM model\n",
    "    lstm_model.save(os.path.join(folder_path, 'lstm_model.h5'))\n",
    "    \n",
    "    # Save scaler\n",
    "    joblib.dump(scaler, os.path.join(folder_path, 'scaler.pkl'))\n",
    "\n",
    "def load_model(folder_path):\n",
    "    # Load ARIMA model\n",
    "    arima_results = joblib.load(os.path.join(folder_path, 'arima_model.pkl'))\n",
    "    \n",
    "    # Load LSTM model\n",
    "    lstm_model = load_model(os.path.join(folder_path, 'lstm_model.h5'))\n",
    "    \n",
    "    # Load scaler\n",
    "    scaler = joblib.load(os.path.join(folder_path, 'scaler.pkl'))\n",
    "    \n",
    "    return arima_results, lstm_model, scaler\n",
    "\n",
    "def make_predictions(arima_results, lstm_model, scaler, test_data, time_steps=60):\n",
    "    predictions = []\n",
    "    test_data = np.array(test_data).reshape(-1, 1)\n",
    "\n",
    "    for i in range(len(test_data)):\n",
    "        # ARIMA prediction\n",
    "        arima_forecast = arima_results.forecast(steps=1)\n",
    "\n",
    "        # LSTM prediction\n",
    "        last_60_days = scaler.transform(test_data[i:i+time_steps])\n",
    "        X_test = np.array([last_60_days])\n",
    "        X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "        lstm_prediction = lstm_model.predict(X_test)\n",
    "        lstm_prediction = scaler.inverse_transform(lstm_prediction)\n",
    "\n",
    "        # Combine predictions\n",
    "        hybrid_prediction = arima_forecast + lstm_prediction[0][0]\n",
    "        predictions.append(hybrid_prediction[0])\n",
    "\n",
    "        # Update ARIMA model\n",
    "        arima_results = arima_results.append(test_data[i])\n",
    "\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    train_data = pd.read_csv('../Data/SBI Train data.csv')\n",
    "    test_data = pd.read_csv('../Data/SBI Test data.csv')\n",
    "\n",
    "    train_close_prices = train_data['Close']\n",
    "    test_close_prices = test_data['Close']\n",
    "\n",
    "    # Create and save the model\n",
    "    arima_results, lstm_model, scaler = create_hybrid_model(train_close_prices)\n",
    "    save_model(arima_results, lstm_model, scaler, 'saved_model')\n",
    "\n",
    "    # Later, load the model and make predictions\n",
    "    loaded_arima, loaded_lstm, loaded_scaler = load_model('saved_model')\n",
    "    predictions = make_predictions(loaded_arima, loaded_lstm, loaded_scaler, test_close_prices)\n",
    "\n",
    "    # Calculate accuracy metrics\n",
    "    mae = mean_absolute_error(test_close_prices, predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(test_close_prices, predictions))\n",
    "    mape = np.mean(np.abs((test_close_prices - predictions) / test_close_prices)) * 100\n",
    "\n",
    "    print(f\"Mean Absolute Error: ${mae:.2f}\")\n",
    "    print(f\"Root Mean Squared Error: ${rmse:.2f}\")\n",
    "    print(f\"Mean Absolute Percentage Error: {mape:.2f}%\")\n",
    "\n",
    "    # Plot results\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(test_data['Date'], test_close_prices, label='Actual Prices')\n",
    "    plt.plot(test_data['Date'], predictions, label='Predicted Prices')\n",
    "    plt.title('Actual vs Predicted Stock Prices')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import joblib  # For saving the ARIMA model\n",
    "import os\n",
    "\n",
    "# Data preparation\n",
    "def prepare_data(data, time_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X.append(data[i:(i + time_steps), 0])\n",
    "        y.append(data[i + time_steps, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Hybrid ARIMA-LSTM Model\n",
    "def hybrid_model(train_data, test_data, time_steps=60, model_dir='./model'):\n",
    "    # Ensure data is a numpy array\n",
    "    train_df = np.array(train_data).reshape(-1, 1)\n",
    "    train_df = pd.DataFrame(train_df).ffill().values\n",
    "\n",
    "    # Create a directory to save models if it doesn't exist\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    # ARIMA Model\n",
    "    arima_model_path = os.path.join(model_dir, 'arima_model.pkl')\n",
    "    if not os.path.exists(arima_model_path):\n",
    "        model_auto = auto_arima(train_df, start_p=1, start_q=1, max_p=3, max_q=3, m=1,\n",
    "                                d=None, seasonal=False, start_P=0, D=0, trace=True,\n",
    "                                error_action='ignore', suppress_warnings=True, stepwise=True)\n",
    "\n",
    "        arima_model = ARIMA(train_df, order=model_auto.order)\n",
    "        arima_results = arima_model.fit()\n",
    "        # Save ARIMA model\n",
    "        joblib.dump(arima_results, arima_model_path)\n",
    "    else:\n",
    "        arima_results = joblib.load(arima_model_path)\n",
    "\n",
    "    # Get ARIMA residuals\n",
    "    arima_residuals = train_df - arima_results.fittedvalues.reshape(-1, 1)\n",
    "    arima_residuals = np.nan_to_num(arima_residuals)\n",
    "\n",
    "    # Prepare data for LSTM\n",
    "    scaler = MinMaxScaler()\n",
    "    residuals_scaled = scaler.fit_transform(arima_residuals)\n",
    "\n",
    "    X, y = prepare_data(residuals_scaled, time_steps)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    # LSTM Model\n",
    "    lstm_model_path = os.path.join(model_dir, 'lstm_model.keras')  # Updated file extension\n",
    "    if not os.path.exists(lstm_model_path):\n",
    "        lstm_model = Sequential([\n",
    "            LSTM(units=50, return_sequences=True, input_shape=(X.shape[1], 1)),\n",
    "            LSTM(units=50),\n",
    "            Dense(units=1)\n",
    "        ])\n",
    "        lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "        # Early stopping and model checkpoint\n",
    "        early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "        model_checkpoint = ModelCheckpoint(lstm_model_path, save_best_only=True, monitor='loss')\n",
    "\n",
    "        # Train LSTM model\n",
    "        lstm_model.fit(X, y, epochs=50, batch_size=32, verbose=1, callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "    else:\n",
    "        lstm_model = load_model(lstm_model_path)\n",
    "\n",
    "    # Make predictions for test data\n",
    "    predictions = []\n",
    "    test_data = np.array(test_data).reshape(-1, 1)\n",
    "    combined_data = np.vstack((train_df, test_data))\n",
    "\n",
    "    for i in range(len(test_data)):\n",
    "        # ARIMA prediction\n",
    "        arima_forecast = arima_results.forecast(steps=1)\n",
    "\n",
    "        # LSTM prediction\n",
    "        last_60_days = scaler.transform(combined_data[-(time_steps+1):-1])\n",
    "        X_test = np.array([last_60_days])\n",
    "        X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "        lstm_prediction = lstm_model.predict(X_test)\n",
    "        lstm_prediction = scaler.inverse_transform(lstm_prediction)\n",
    "\n",
    "        # Combine predictions\n",
    "        hybrid_prediction = arima_forecast + lstm_prediction[0][0]\n",
    "        predictions.append(hybrid_prediction[0])\n",
    "\n",
    "        # Update ARIMA model with test data\n",
    "        arima_results = arima_model.append(test_data[i]).fit()\n",
    "\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Load and prepare data\n",
    "train_data = pd.read_csv('../Data/SBI Train data.csv')\n",
    "test_data = pd.read_csv('../Data/SBI Test data.csv')\n",
    "\n",
    "train_close_prices = train_data['Close']\n",
    "test_close_prices = test_data['Close']\n",
    "\n",
    "# Make predictions\n",
    "predictions = hybrid_model(train_close_prices, test_close_prices)\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "mae = mean_absolute_error(test_close_prices, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(test_close_prices, predictions))\n",
    "\n",
    "print(f\"Mean Absolute Error: ${mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: ${rmse:.2f}\")\n",
    "\n",
    "# Calculate Mean Absolute Percentage Error (MAPE)\n",
    "mape = np.mean(np.abs((test_close_prices - predictions) / test_close_prices)) * 100\n",
    "print(f\"Mean Absolute Percentage Error: {mape:.2f}%\")\n",
    "\n",
    "# Plot actual vs predicted prices\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(test_data['Date'], test_close_prices, label='Actual Prices')\n",
    "plt.plot(test_data['Date'], predictions, label='Predicted Prices')\n",
    "plt.title('Actual vs Predicted Stock Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
